{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9280309,"sourceType":"datasetVersion","datasetId":5574334},{"sourceId":9283489,"sourceType":"datasetVersion","datasetId":5619380},{"sourceId":9447847,"sourceType":"datasetVersion","datasetId":5742253},{"sourceId":9502644,"sourceType":"datasetVersion","datasetId":5783363},{"sourceId":204814631,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense,Dropout\nimport tensorflow as tf\nimport random\nfrom sklearn.model_selection import TimeSeriesSplit\nimport statsmodels.api as sm\n\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\n\nimport lightgbm\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR\nfrom lightgbm import early_stopping ","metadata":{"id":"aiiMxW4BG-DP","execution":{"iopub.status.busy":"2024-11-02T13:56:23.002060Z","iopub.execute_input":"2024-11-02T13:56:23.002462Z","iopub.status.idle":"2024-11-02T13:56:44.419931Z","shell.execute_reply.started":"2024-11-02T13:56:23.002432Z","shell.execute_reply":"2024-11-02T13:56:44.418292Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-11-02 13:56:26.790316: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-11-02 13:56:26.790545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-11-02 13:56:26.993312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:44.422679Z","iopub.execute_input":"2024-11-02T13:56:44.423683Z","iopub.status.idle":"2024-11-02T13:56:44.467719Z","shell.execute_reply.started":"2024-11-02T13:56:44.423632Z","shell.execute_reply":"2024-11-02T13:56:44.465811Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/amirkabirdam/holiday.csv\n/kaggle/input/amirkabirdam/dam12.csv\n/kaggle/input/d/homaabedinzadeh/futuredays/90days.csv\n/kaggle/input/d/homaabedinzadeh/holidayname/holidayname.csv\n/kaggle/input/feature-engineering/__results__.html\n/kaggle/input/feature-engineering/__notebook__.ipynb\n/kaggle/input/feature-engineering/__output__.json\n/kaggle/input/feature-engineering/finaldatset.csv\n/kaggle/input/feature-engineering/custom.css\n/kaggle/input/climate-indeices/ONI.xlsx\n/kaggle/input/climate-indeices/ENSO.xlsx\n/kaggle/input/climate-indeices/AMO.xlsx\n/kaggle/input/climate-indeices/NAO.xlsx\n/kaggle/input/climate-indeices/SOI.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T10:24:30.471010Z","iopub.execute_input":"2024-11-02T10:24:30.471435Z","iopub.status.idle":"2024-11-02T10:24:30.477075Z","shell.execute_reply.started":"2024-11-02T10:24:30.471401Z","shell.execute_reply":"2024-11-02T10:24:30.475909Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/feature-engineering/finaldatset.csv')\n","metadata":{"id":"miFvtwBvG-DR","executionInfo":{"status":"ok","timestamp":1725614061565,"user_tz":-210,"elapsed":459,"user":{"displayName":"Mohsen Yazdinejad","userId":"00188286051626590191"}},"outputId":"2791eec4-02cc-40e2-979a-6858214ab3a0","execution":{"iopub.status.busy":"2024-11-02T13:56:44.469211Z","iopub.execute_input":"2024-11-02T13:56:44.469570Z","iopub.status.idle":"2024-11-02T13:56:50.660907Z","shell.execute_reply.started":"2024-11-02T13:56:44.469541Z","shell.execute_reply":"2024-11-02T13:56:50.659451Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.drop('DateRow', inplace=True , axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.664527Z","iopub.execute_input":"2024-11-02T13:56:50.665075Z","iopub.status.idle":"2024-11-02T13:56:50.725157Z","shell.execute_reply.started":"2024-11-02T13:56:50.665032Z","shell.execute_reply":"2024-11-02T13:56:50.723862Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.726812Z","iopub.execute_input":"2024-11-02T13:56:50.727315Z","iopub.status.idle":"2024-11-02T13:56:50.737280Z","shell.execute_reply.started":"2024-11-02T13:56:50.727275Z","shell.execute_reply":"2024-11-02T13:56:50.736048Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['soi_shift_1', 'soi_shiftdiv_1', 'soi_shift_3', 'soi_shiftdiv_3',\n       'soi_shift_6', 'soi_shiftdiv_6', 'soi_shift_9', 'soi_shiftdiv_9',\n       'soi_shift_12', 'soi_shiftdiv_12',\n       ...\n       'BareshBarf_in_shift_1_x_BareshBarf_in_shift_2',\n       'BareshBarf_in_shift_1_x_BareshBarf_in_shift_3',\n       'BareshBarf_in_shift_1_x_BareshBarf_in_shift_4',\n       'BareshBarf_in_shift_1_x_BareshBarf_in_shift_5',\n       'BareshBarf_in_shift_2_x_BareshBarf_in_shift_3',\n       'BareshBarf_in_shift_2_x_BareshBarf_in_shift_4',\n       'BareshBarf_in_shift_2_x_BareshBarf_in_shift_5',\n       'BareshBarf_in_shift_3_x_BareshBarf_in_shift_4',\n       'BareshBarf_in_shift_3_x_BareshBarf_in_shift_5',\n       'BareshBarf_in_shift_4_x_BareshBarf_in_shift_5'],\n      dtype='object', length=2118)"},"metadata":{}}]},{"cell_type":"code","source":"horizon=-15","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.738566Z","iopub.execute_input":"2024-11-02T13:56:50.738903Z","iopub.status.idle":"2024-11-02T13:56:50.750238Z","shell.execute_reply.started":"2024-11-02T13:56:50.738877Z","shell.execute_reply":"2024-11-02T13:56:50.748877Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"target = df['Total_in'].shift(horizon)\n\ntarget.dropna(inplace=True)","metadata":{"id":"hcVAWHdkXj-Y","execution":{"iopub.status.busy":"2024-11-02T13:56:50.751752Z","iopub.execute_input":"2024-11-02T13:56:50.752184Z","iopub.status.idle":"2024-11-02T13:56:50.767582Z","shell.execute_reply.started":"2024-11-02T13:56:50.752153Z","shell.execute_reply":"2024-11-02T13:56:50.766206Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.769322Z","iopub.execute_input":"2024-11-02T13:56:50.769707Z","iopub.status.idle":"2024-11-02T13:56:50.817279Z","shell.execute_reply.started":"2024-11-02T13:56:50.769676Z","shell.execute_reply":"2024-11-02T13:56:50.816070Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   soi_shift_1  soi_shiftdiv_1  soi_shift_3  soi_shiftdiv_3  soi_shift_6  \\\n0          0.5            -1.0          0.3            -0.6          0.9   \n1          0.5            -1.0          0.3            -0.6          0.9   \n2          0.5            -1.0          0.3            -0.6          0.9   \n3          0.5            -1.0          0.3            -0.6          0.9   \n4          0.5            -1.0          0.3            -0.6          0.9   \n\n   soi_shiftdiv_6  soi_shift_9  soi_shiftdiv_9  soi_shift_12  soi_shiftdiv_12  \\\n0            -1.8         -0.5             1.0          -0.3              0.6   \n1            -1.8         -0.5             1.0          -0.3              0.6   \n2            -1.8         -0.5             1.0          -0.3              0.6   \n3            -1.8         -0.5             1.0          -0.3              0.6   \n4            -1.8         -0.5             1.0          -0.3              0.6   \n\n   ...  BareshBarf_in_shift_1_x_BareshBarf_in_shift_2  \\\n0  ...                                  213575.821963   \n1  ...                                  213575.821963   \n2  ...                                  213575.821963   \n3  ...                                  213575.821963   \n4  ...                                  213575.821963   \n\n   BareshBarf_in_shift_1_x_BareshBarf_in_shift_3  \\\n0                                  220695.016028   \n1                                  220695.016028   \n2                                  220695.016028   \n3                                  220695.016028   \n4                                  220695.016028   \n\n   BareshBarf_in_shift_1_x_BareshBarf_in_shift_4  \\\n0                                  213575.821963   \n1                                  213575.821963   \n2                                  213575.821963   \n3                                  213575.821963   \n4                                  213575.821963   \n\n   BareshBarf_in_shift_1_x_BareshBarf_in_shift_5  \\\n0                                  220695.016028   \n1                                  220695.016028   \n2                                  220695.016028   \n3                                  220695.016028   \n4                                  220695.016028   \n\n   BareshBarf_in_shift_2_x_BareshBarf_in_shift_3  \\\n0                                   197230.60971   \n1                                   197230.60971   \n2                                   197230.60971   \n3                                   197230.60971   \n4                                   197230.60971   \n\n   BareshBarf_in_shift_2_x_BareshBarf_in_shift_4  \\\n0                                  190868.331977   \n1                                  190868.331977   \n2                                  190868.331977   \n3                                  190868.331977   \n4                                  190868.331977   \n\n   BareshBarf_in_shift_2_x_BareshBarf_in_shift_5  \\\n0                                   197230.60971   \n1                                   197230.60971   \n2                                   197230.60971   \n3                                   197230.60971   \n4                                   197230.60971   \n\n   BareshBarf_in_shift_3_x_BareshBarf_in_shift_4  \\\n0                                   197230.60971   \n1                                   197230.60971   \n2                                   197230.60971   \n3                                   197230.60971   \n4                                   197230.60971   \n\n   BareshBarf_in_shift_3_x_BareshBarf_in_shift_5  \\\n0                                  203804.963367   \n1                                  203804.963367   \n2                                  203804.963367   \n3                                  203804.963367   \n4                                  203804.963367   \n\n   BareshBarf_in_shift_4_x_BareshBarf_in_shift_5  \n0                                   197230.60971  \n1                                   197230.60971  \n2                                   197230.60971  \n3                                   197230.60971  \n4                                   197230.60971  \n\n[5 rows x 2118 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>soi_shift_1</th>\n      <th>soi_shiftdiv_1</th>\n      <th>soi_shift_3</th>\n      <th>soi_shiftdiv_3</th>\n      <th>soi_shift_6</th>\n      <th>soi_shiftdiv_6</th>\n      <th>soi_shift_9</th>\n      <th>soi_shiftdiv_9</th>\n      <th>soi_shift_12</th>\n      <th>soi_shiftdiv_12</th>\n      <th>...</th>\n      <th>BareshBarf_in_shift_1_x_BareshBarf_in_shift_2</th>\n      <th>BareshBarf_in_shift_1_x_BareshBarf_in_shift_3</th>\n      <th>BareshBarf_in_shift_1_x_BareshBarf_in_shift_4</th>\n      <th>BareshBarf_in_shift_1_x_BareshBarf_in_shift_5</th>\n      <th>BareshBarf_in_shift_2_x_BareshBarf_in_shift_3</th>\n      <th>BareshBarf_in_shift_2_x_BareshBarf_in_shift_4</th>\n      <th>BareshBarf_in_shift_2_x_BareshBarf_in_shift_5</th>\n      <th>BareshBarf_in_shift_3_x_BareshBarf_in_shift_4</th>\n      <th>BareshBarf_in_shift_3_x_BareshBarf_in_shift_5</th>\n      <th>BareshBarf_in_shift_4_x_BareshBarf_in_shift_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>0.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.8</td>\n      <td>-0.5</td>\n      <td>1.0</td>\n      <td>-0.3</td>\n      <td>0.6</td>\n      <td>...</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>197230.60971</td>\n      <td>190868.331977</td>\n      <td>197230.60971</td>\n      <td>197230.60971</td>\n      <td>203804.963367</td>\n      <td>197230.60971</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>0.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.8</td>\n      <td>-0.5</td>\n      <td>1.0</td>\n      <td>-0.3</td>\n      <td>0.6</td>\n      <td>...</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>197230.60971</td>\n      <td>190868.331977</td>\n      <td>197230.60971</td>\n      <td>197230.60971</td>\n      <td>203804.963367</td>\n      <td>197230.60971</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>0.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.8</td>\n      <td>-0.5</td>\n      <td>1.0</td>\n      <td>-0.3</td>\n      <td>0.6</td>\n      <td>...</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>197230.60971</td>\n      <td>190868.331977</td>\n      <td>197230.60971</td>\n      <td>197230.60971</td>\n      <td>203804.963367</td>\n      <td>197230.60971</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>0.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.8</td>\n      <td>-0.5</td>\n      <td>1.0</td>\n      <td>-0.3</td>\n      <td>0.6</td>\n      <td>...</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>197230.60971</td>\n      <td>190868.331977</td>\n      <td>197230.60971</td>\n      <td>197230.60971</td>\n      <td>203804.963367</td>\n      <td>197230.60971</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>-1.0</td>\n      <td>0.3</td>\n      <td>-0.6</td>\n      <td>0.9</td>\n      <td>-1.8</td>\n      <td>-0.5</td>\n      <td>1.0</td>\n      <td>-0.3</td>\n      <td>0.6</td>\n      <td>...</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>213575.821963</td>\n      <td>220695.016028</td>\n      <td>197230.60971</td>\n      <td>190868.331977</td>\n      <td>197230.60971</td>\n      <td>197230.60971</td>\n      <td>203804.963367</td>\n      <td>197230.60971</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2118 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"y=target\n\nx = df[:horizon]\n#. drop(target,axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.818562Z","iopub.execute_input":"2024-11-02T13:56:50.818933Z","iopub.status.idle":"2024-11-02T13:56:50.825352Z","shell.execute_reply.started":"2024-11-02T13:56:50.818901Z","shell.execute_reply":"2024-11-02T13:56:50.824035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.828894Z","iopub.execute_input":"2024-11-02T13:56:50.829478Z","iopub.status.idle":"2024-11-02T13:56:50.839908Z","shell.execute_reply.started":"2024-11-02T13:56:50.829439Z","shell.execute_reply":"2024-11-02T13:56:50.838330Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(7290, 2118)"},"metadata":{}}]},{"cell_type":"code","source":"len(y)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.841646Z","iopub.execute_input":"2024-11-02T13:56:50.842034Z","iopub.status.idle":"2024-11-02T13:56:50.854117Z","shell.execute_reply.started":"2024-11-02T13:56:50.842005Z","shell.execute_reply":"2024-11-02T13:56:50.852657Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"7290"},"metadata":{}}]},{"cell_type":"code","source":"x.replace([np.inf, -np.inf], np.nan, inplace=True)\nx.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:50.855610Z","iopub.execute_input":"2024-11-02T13:56:50.856071Z","iopub.status.idle":"2024-11-02T13:56:51.669960Z","shell.execute_reply.started":"2024-11-02T13:56:50.856037Z","shell.execute_reply":"2024-11-02T13:56:51.668687Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/781971186.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x.replace([np.inf, -np.inf], np.nan, inplace=True)\n/tmp/ipykernel_33/781971186.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  x.fillna(0, inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"x.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-02T13:56:51.671593Z","iopub.execute_input":"2024-11-02T13:56:51.672077Z","iopub.status.idle":"2024-11-02T13:56:51.680265Z","shell.execute_reply.started":"2024-11-02T13:56:51.672037Z","shell.execute_reply":"2024-11-02T13:56:51.678760Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(7290, 2118)"},"metadata":{}}]},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits = 20)\ntest_rmse = []\ntrain_rmse= []\ntest_r2 = []\ntrain_r2=[]\ntest_mape=[]\nXGB_predictions = pd.DataFrame(columns=['predictXGB'])\n\n\ni=0\nfor train_index, test_index in tscv.split(x):\n    i+=1\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n    if i>=13:\n        \n        model = xgb.XGBRegressor(n_estimators=10000,early_stopping_rounds=10, learning_rate=0.07,  max_depth= 15 ,colsample_bytree= 0.85,  n_jobs=4)\n        \n        model.fit(X_train, Y_train,sample_weight=X_train['std_TotalAbBarfVBaran_in'], eval_set=[(X_test,Y_test)],verbose=False)\n\n    # Predictions\n        test_predict = model.predict(X_test)\n        train_predict = model.predict(X_train)\n        Y_test= (np.exp(Y_test)-100)/1000\n        test_predict= (np.exp(test_predict)-100)/1000\n        \n        test_rmse.append ( np.sqrt(mean_squared_error(Y_test, test_predict)))\n        train_rmse.append ( np.sqrt(mean_squared_error(Y_train, train_predict)))\n       \n        test_mape.append (mean_absolute_percentage_error(Y_test, test_predict))\n        df_temp = pd.DataFrame({'predictXGB': test_predict})\n\n        # استفاده از pd.concat برای اضافه کردن پیش‌بینی‌ها به دیتافریم اصلی\n        XGB_predictions = pd.concat([XGB_predictions, df_temp], ignore_index=True)\n        \n        test_r2 .append ( r2_score(Y_test, test_predict))\n        train_r2 .append ( r2_score(Y_train, train_predict))\n        print ('rmse:',np.sqrt(mean_squared_error(Y_test, test_predict)))\n        print ('r2:', r2_score(Y_test, test_predict))\n        print ('mape:', mean_absolute_percentage_error(Y_test, test_predict))\n\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,Y_test, color='blue')\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,test_predict, color='red')\nprint(\"rmsetrain:\",np.mean(train_rmse),\"rmsetest\",np.mean(test_rmse))\nprint (\"r2train:\",np.mean(train_r2),'r2test:',np.mean(test_r2) )\n\nprint ('mapetest:',np.mean(test_mape))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XGB_predictions.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimp = pd.DataFrame({'Importance':model.feature_importances_,'Feature':x.columns})\nfe=imp.sort_values(by='Importance',ascending=False).head(50)\nfe.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits = 20)\ntest_rmse = []\ntrain_rmse= []\ntest_r2 = []\ntrain_r2=[]\ntest_mape=[]\nLGB_predictions = pd.DataFrame(columns=['predictLGB'])\nTestSet=pd.DataFrame(columns=['Test'])\ni=0\nfor train_index, test_index in tscv.split(x):\n    \n    i+=1\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n    print (train_index.min(),train_index.max())\n    print (test_index.min(),test_index.max())\n    if i>=3:\n        lgb = lightgbm.LGBMRegressor( n_estimators=10000, num_leaves=35, learning_rate=0.04, colsample_bytree=0.9,verbose=0)\n\n        lgb.fit(X_train, Y_train,sample_weight=X_train['Total_in_shift_1'], eval_set=(X_test,Y_test),callbacks=([early_stopping(stopping_rounds=60)]))\n\n        test_predict = lgb.predict(X_test, num_iteration=lgb.best_iteration_)\n        train_predict = lgb.predict(X_train, num_iteration=lgb.best_iteration_)\n        Y_test= (np.exp(Y_test)-100)/1000\n        test_predict= (np.exp(test_predict)-100)/1000\n        \n        test_rmse.append ( np.sqrt(mean_squared_error(Y_test, test_predict)))\n        train_rmse.append ( np.sqrt(mean_squared_error(Y_train, train_predict)))\n\n        test_r2 .append ( r2_score(Y_test, test_predict))\n        train_r2 .append ( r2_score(Y_train, train_predict))\n        test_mape.append (mean_absolute_percentage_error(Y_test, test_predict))\n        df_temp = pd.DataFrame({'predictLGB': test_predict})\n        test_temp = pd.DataFrame({'Test': Y_test})\n        # استفاده از pd.concat برای اضافه کردن پیش‌بینی‌ها به دیتافریم اصلی\n        LGB_predictions= pd.concat([LGB_predictions, df_temp], ignore_index=True)\n        TestSet= pd.concat([TestSet, test_temp], ignore_index=True)\n        \n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,Y_test, color='blue')\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,test_predict, color='red')\n        print ('rmse:',np.sqrt(mean_squared_error(Y_test, test_predict)))\n        print ('r2:', r2_score(Y_test, test_predict))\n        print ('mape:', mean_absolute_percentage_error(Y_test, test_predict))\n        #plt.show()\nprint(\"rmsetrain:\",np.mean(train_rmse),\"rmsetest\",np.mean(test_rmse))\nprint (\"r2train:\",np.mean(train_r2),'r2test:',np.mean(test_r2) )\n\nprint ('mapetest:',np.mean(test_mape))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:26:27.469422Z","iopub.execute_input":"2024-11-02T14:26:27.469861Z","iopub.status.idle":"2024-11-02T14:41:14.657964Z","shell.execute_reply.started":"2024-11-02T14:26:27.469831Z","shell.execute_reply":"2024-11-02T14:41:14.656434Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"0 349\n350 696\n0 696\n697 1043\n0 1043\n1044 1390\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[48]\tvalid_0's l2: 0.298561\nrmse: 1.2313977036666317\nr2: 0.4420438858447838\nmape: 0.6471344040489551\n0 1390\n1391 1737\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2982105990.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  LGB_predictions= pd.concat([LGB_predictions, df_temp], ignore_index=True)\n/tmp/ipykernel_33/2982105990.py:37: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  TestSet= pd.concat([TestSet, test_temp], ignore_index=True)\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[65]\tvalid_0's l2: 0.239812\nrmse: 0.5134482926390519\nr2: 0.10941257512522029\nmape: 0.6943029084241145\n0 1737\n1738 2084\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[28]\tvalid_0's l2: 0.0967206\nrmse: 0.3511364066083695\nr2: 0.8189982637378663\nmape: 0.3740912890709193\n0 2084\n2085 2431\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[156]\tvalid_0's l2: 0.0537447\nrmse: 0.4117460783186847\nr2: 0.8168449434674291\nmape: 0.17180845618264723\n0 2431\n2432 2778\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[124]\tvalid_0's l2: 0.205401\nrmse: 0.46251492364247243\nr2: 0.7964377470857323\nmape: 0.5914759452804013\n0 2778\n2779 3125\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[58]\tvalid_0's l2: 0.188758\nrmse: 0.8259353023954384\nr2: 0.571071009094804\nmape: 0.2570545003993771\n0 3125\n3126 3472\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[146]\tvalid_0's l2: 0.0625652\nrmse: 0.2632250430075523\nr2: 0.7583490906394706\nmape: 0.24495484240160517\n0 3472\n3473 3819\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[33]\tvalid_0's l2: 0.0992548\nrmse: 0.299947415933613\nr2: 0.5805674208324805\nmape: 0.4023196117559612\n0 3819\n3820 4166\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[162]\tvalid_0's l2: 0.129693\nrmse: 0.9052356698697311\nr2: 0.48384913506930816\nmape: 0.41739291834686854\n0 4166\n4167 4513\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[284]\tvalid_0's l2: 0.0913539\nrmse: 0.6616078146233525\nr2: 0.6386695950996238\nmape: 0.2342249350332432\n0 4513\n4514 4860\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[173]\tvalid_0's l2: 0.0683953\nrmse: 0.5117772620669286\nr2: 0.7966893125606063\nmape: 0.23507331438179088\n0 4860\n4861 5207\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[131]\tvalid_0's l2: 0.0604345\nrmse: 0.21592583022614062\nr2: 0.937482657928921\nmape: 0.26367454175138577\n0 5207\n5208 5554\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[58]\tvalid_0's l2: 0.0525626\nrmse: 0.4520771952720532\nr2: 0.5944001852843909\nmape: 0.1778521695301056\n0 5554\n5555 5901\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[495]\tvalid_0's l2: 0.0789537\nrmse: 0.9045988067362053\nr2: 0.6903942761456782\nmape: 0.20842218813907679\n0 5901\n5902 6248\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[139]\tvalid_0's l2: 0.0461553\nrmse: 0.49403733213777906\nr2: 0.8576656957558609\nmape: 0.1536936334880468\n0 6248\n6249 6595\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[109]\tvalid_0's l2: 0.0384717\nrmse: 0.26768884999713327\nr2: 0.8532388332631542\nmape: 0.17322752517820786\n0 6595\n6596 6942\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[88]\tvalid_0's l2: 0.043406\nrmse: 0.2664623410274649\nr2: 0.8013144507970708\nmape: 0.20105607850288051\n0 6942\n6943 7289\nTraining until validation scores don't improve for 60 rounds\nEarly stopping, best iteration is:\n[118]\tvalid_0's l2: 0.0512685\nrmse: 0.41838613726674745\nr2: 0.6647557492907084\nmape: 0.1929014503880471\nrmsetrain: 0.1107273789011509 rmsetest 0.5253971336352972\nr2train: 0.9710780229763096 r2test: 0.678454712612395\nmapetest: 0.31337003957242404\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"76.84/(76.84+ 75.55)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" 75.55/(76.84+ 75.55)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final=pd.concat ([LGB_predictions ,XGB_predictions, TestSet], axis=1) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final['mean_column'] = ((final['predictLGB']*0.50) + (final['predictXGB']*0.49)) \n\nfinal.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_score(final['Test'], final['mean_column'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp = pd.DataFrame({'Importance':lgb.feature_importances_,'Feature':x.columns})\nfe=imp.sort_values(by='Importance',ascending=False).head(50)\nfe.head(50)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T11:34:59.701727Z","iopub.execute_input":"2024-11-02T11:34:59.702093Z","iopub.status.idle":"2024-11-02T11:34:59.722170Z","shell.execute_reply.started":"2024-11-02T11:34:59.702062Z","shell.execute_reply":"2024-11-02T11:34:59.721033Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"      Importance                                 Feature\n2058         181                  meanbeforeyearTotal_in\n1976          63                   Total_in_rollingmin_7\n519           62     TotalAbBarfVBaran_in_rollingstd_180\n1609          50      DarajeHararatTar6_5_rollingmax_180\n1402          44   DarajeHararatKhosk6_5_rollingmean_180\n1606          37     DarajeHararatTar6_5_rollingmean_180\n2004          36              Total_in_div_rollingstd_90\n1470          31  DarajeHararatKhosk12_5_rollingmean_180\n1982          31                 Total_in_rollingmean_30\n1966          31                        Total_in_shift_7\n1983          30                  Total_in_rollingstd_30\n723           29               Tabkhir_in_rollingstd_180\n1974          26                  Total_in_rollingmean_7\n1675          26     DarajeHararatTar12_5_rollingstd_180\n586           25     MinDarajehararat_in_rollingmean_180\n1539          24   DarajeHararatKhosk18_5_rollingstd_180\n1990          24                 Total_in_rollingmean_60\n1471          24   DarajeHararatKhosk12_5_rollingstd_180\n1669          23     DarajeHararatTar12_5_rollingmax_120\n1677          22     DarajeHararatTar12_5_rollingmax_180\n1977          21                   Total_in_rollingmax_7\n1973          20                   Total_in_shiftdiv_180\n2019          20            Total_in_div_rollingmean_180\n1988          19              Total_in_div_rollingstd_30\n1743          19     DarajeHararatTar18_5_rollingstd_180\n707           19                Tabkhir_in_rollingstd_90\n1465          18   DarajeHararatKhosk12_5_rollingmax_120\n1984          18                  Total_in_rollingmin_30\n722           17              Tabkhir_in_rollingmean_180\n1546          17  DarajeHararatKhosk18_5_rollingmean_365\n2055          17                             day_of_year\n1980          16               Total_in_div_rollingstd_7\n699           15                Tabkhir_in_rollingstd_60\n527           15     TotalAbBarfVBaran_in_rollingstd_365\n503           15      TotalAbBarfVBaran_in_rollingstd_90\n1651          15      DarajeHararatTar12_5_rollingstd_60\n1947          14             NamNesbi18_5_rollingstd_180\n526           14    TotalAbBarfVBaran_in_rollingmean_365\n1463          14   DarajeHararatKhosk12_5_rollingstd_120\n1635          14       DarajeHararatTar12_5_rollingstd_7\n1996          13              Total_in_div_rollingstd_60\n1523          13    DarajeHararatKhosk18_5_rollingstd_90\n510           13    TotalAbBarfVBaran_in_rollingmean_120\n1841          13               NamNesbi12_5_rollingmax_7\n1599          12      DarajeHararatTar6_5_rollingstd_120\n1771          12                NamNesbi6_5_rollingstd_7\n19            12                        soi_rollingstd_3\n1610          12      DarajeHararatTar6_5_rollingsum_180\n563           12       MinDarajehararat_in_rollingstd_60\n1735          12     DarajeHararatTar18_5_rollingstd_120","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n      <th>Feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2058</th>\n      <td>181</td>\n      <td>meanbeforeyearTotal_in</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>63</td>\n      <td>Total_in_rollingmin_7</td>\n    </tr>\n    <tr>\n      <th>519</th>\n      <td>62</td>\n      <td>TotalAbBarfVBaran_in_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>1609</th>\n      <td>50</td>\n      <td>DarajeHararatTar6_5_rollingmax_180</td>\n    </tr>\n    <tr>\n      <th>1402</th>\n      <td>44</td>\n      <td>DarajeHararatKhosk6_5_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>1606</th>\n      <td>37</td>\n      <td>DarajeHararatTar6_5_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>2004</th>\n      <td>36</td>\n      <td>Total_in_div_rollingstd_90</td>\n    </tr>\n    <tr>\n      <th>1470</th>\n      <td>31</td>\n      <td>DarajeHararatKhosk12_5_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>1982</th>\n      <td>31</td>\n      <td>Total_in_rollingmean_30</td>\n    </tr>\n    <tr>\n      <th>1966</th>\n      <td>31</td>\n      <td>Total_in_shift_7</td>\n    </tr>\n    <tr>\n      <th>1983</th>\n      <td>30</td>\n      <td>Total_in_rollingstd_30</td>\n    </tr>\n    <tr>\n      <th>723</th>\n      <td>29</td>\n      <td>Tabkhir_in_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>26</td>\n      <td>Total_in_rollingmean_7</td>\n    </tr>\n    <tr>\n      <th>1675</th>\n      <td>26</td>\n      <td>DarajeHararatTar12_5_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>586</th>\n      <td>25</td>\n      <td>MinDarajehararat_in_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>1539</th>\n      <td>24</td>\n      <td>DarajeHararatKhosk18_5_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>24</td>\n      <td>Total_in_rollingmean_60</td>\n    </tr>\n    <tr>\n      <th>1471</th>\n      <td>24</td>\n      <td>DarajeHararatKhosk12_5_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>1669</th>\n      <td>23</td>\n      <td>DarajeHararatTar12_5_rollingmax_120</td>\n    </tr>\n    <tr>\n      <th>1677</th>\n      <td>22</td>\n      <td>DarajeHararatTar12_5_rollingmax_180</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>21</td>\n      <td>Total_in_rollingmax_7</td>\n    </tr>\n    <tr>\n      <th>1973</th>\n      <td>20</td>\n      <td>Total_in_shiftdiv_180</td>\n    </tr>\n    <tr>\n      <th>2019</th>\n      <td>20</td>\n      <td>Total_in_div_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>1988</th>\n      <td>19</td>\n      <td>Total_in_div_rollingstd_30</td>\n    </tr>\n    <tr>\n      <th>1743</th>\n      <td>19</td>\n      <td>DarajeHararatTar18_5_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>707</th>\n      <td>19</td>\n      <td>Tabkhir_in_rollingstd_90</td>\n    </tr>\n    <tr>\n      <th>1465</th>\n      <td>18</td>\n      <td>DarajeHararatKhosk12_5_rollingmax_120</td>\n    </tr>\n    <tr>\n      <th>1984</th>\n      <td>18</td>\n      <td>Total_in_rollingmin_30</td>\n    </tr>\n    <tr>\n      <th>722</th>\n      <td>17</td>\n      <td>Tabkhir_in_rollingmean_180</td>\n    </tr>\n    <tr>\n      <th>1546</th>\n      <td>17</td>\n      <td>DarajeHararatKhosk18_5_rollingmean_365</td>\n    </tr>\n    <tr>\n      <th>2055</th>\n      <td>17</td>\n      <td>day_of_year</td>\n    </tr>\n    <tr>\n      <th>1980</th>\n      <td>16</td>\n      <td>Total_in_div_rollingstd_7</td>\n    </tr>\n    <tr>\n      <th>699</th>\n      <td>15</td>\n      <td>Tabkhir_in_rollingstd_60</td>\n    </tr>\n    <tr>\n      <th>527</th>\n      <td>15</td>\n      <td>TotalAbBarfVBaran_in_rollingstd_365</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>15</td>\n      <td>TotalAbBarfVBaran_in_rollingstd_90</td>\n    </tr>\n    <tr>\n      <th>1651</th>\n      <td>15</td>\n      <td>DarajeHararatTar12_5_rollingstd_60</td>\n    </tr>\n    <tr>\n      <th>1947</th>\n      <td>14</td>\n      <td>NamNesbi18_5_rollingstd_180</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>14</td>\n      <td>TotalAbBarfVBaran_in_rollingmean_365</td>\n    </tr>\n    <tr>\n      <th>1463</th>\n      <td>14</td>\n      <td>DarajeHararatKhosk12_5_rollingstd_120</td>\n    </tr>\n    <tr>\n      <th>1635</th>\n      <td>14</td>\n      <td>DarajeHararatTar12_5_rollingstd_7</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>13</td>\n      <td>Total_in_div_rollingstd_60</td>\n    </tr>\n    <tr>\n      <th>1523</th>\n      <td>13</td>\n      <td>DarajeHararatKhosk18_5_rollingstd_90</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>13</td>\n      <td>TotalAbBarfVBaran_in_rollingmean_120</td>\n    </tr>\n    <tr>\n      <th>1841</th>\n      <td>13</td>\n      <td>NamNesbi12_5_rollingmax_7</td>\n    </tr>\n    <tr>\n      <th>1599</th>\n      <td>12</td>\n      <td>DarajeHararatTar6_5_rollingstd_120</td>\n    </tr>\n    <tr>\n      <th>1771</th>\n      <td>12</td>\n      <td>NamNesbi6_5_rollingstd_7</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>12</td>\n      <td>soi_rollingstd_3</td>\n    </tr>\n    <tr>\n      <th>1610</th>\n      <td>12</td>\n      <td>DarajeHararatTar6_5_rollingsum_180</td>\n    </tr>\n    <tr>\n      <th>563</th>\n      <td>12</td>\n      <td>MinDarajehararat_in_rollingstd_60</td>\n    </tr>\n    <tr>\n      <th>1735</th>\n      <td>12</td>\n      <td>DarajeHararatTar18_5_rollingstd_120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ndf.dropna(inplace=True, axis=1)\ndf.shape\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.fillna(0, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target=df['Total_in'].shift(horizon)\ny=target\n\n#x = scaled_df. drop(columns =[ target ],axis=1)#,'index'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df.drop(columns=['Total_in'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(x)\nscaled_df = pd.DataFrame(scaled_data, columns=x.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=scaled_df[:horizon]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.dropna(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tscv = TimeSeriesSplit(n_splits = 20)\ntest_rmse = []\ntrain_rmse= []\ntest_r2 = []\ntrain_r2=[]\ntest_mape=[]\npredictMLP=[]\ni=0\nfor train_index, test_index in tscv.split(x):\n    i+=1\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n    if i>=13:\n        \n        mlp = MLPRegressor(hidden_layer_sizes=(1024, 512, 256), activation='relu', solver='adam', max_iter=300,learning_rate='constant', early_stopping=True,alpha=  0.0001 , batch_size=64)\n\n        mlp.fit(X_train, Y_train )\n\n        test_predict = mlp.predict(X_test)\n        train_predict = mlp.predict(X_train)\n        \n        test_rmse.append ( np.sqrt(mean_squared_error(Y_test, test_predict)))\n        train_rmse.append ( np.sqrt(mean_squared_error(Y_train, train_predict)))\n        \n        test_r2 .append ( r2_score(Y_test, test_predict))\n        train_r2 .append ( r2_score(Y_train, train_predict))\n        test_mape.append (mean_absolute_percentage_error(Y_test, test_predict))\n        Y_test= (np.exp(Y_test)-100)/1000\n        test_predict= (np.exp(test_predict)-100)/1000\n        predictMLP.append ( test_predict)\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,Y_test, color='blue')\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,test_predict, color='red')\n        print ('rmse:',np.sqrt(mean_squared_error(Y_test, test_predict)))\n        print ('r2:', r2_score(Y_test, test_predict))\n        print ('mape:', mean_absolute_percentage_error(Y_test, test_predict))\n        \nprint(\"rmsetrain:\",np.mean(train_rmse),\"rmsetest\",np.mean(test_rmse))\nprint (\"r2train:\",np.mean(train_r2),'r2test:',np.mean(test_r2) )\nprint ('mapetest:',np.mean(test_mape))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scv = TimeSeriesSplit(n_splits = 20)\ntest_rmse = []\ntrain_rmse= []\ntest_r2 = []\ntrain_r2=[]\ntest_mape=[]\npredictSVR=[]\ni=0\nfor train_index, test_index in tscv.split(x):\n    i+=1\n    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n    if i>=13:\n        \n        svr = SVR(kernel='rbf', C=1.0, epsilon=0.001)\n\n        # آموزش مدل\n        svr.fit(X_train, Y_train)\n\n        # پیش‌بینی\n        test_predict = svr.predict(X_test)\n        train_predict = svr.predict(X_train)\n        predictSVR.append(test_predict)\n        test_rmse.append ( np.sqrt(mean_squared_error(Y_test, test_predict)))\n        train_rmse.append ( np.sqrt(mean_squared_error(Y_train, train_predict)))\n        \n        test_r2 .append ( r2_score(Y_test, test_predict))\n        train_r2 .append ( r2_score(Y_train, train_predict))\n        test_mape.append (mean_absolute_percentage_error(Y_test, test_predict))\n        Y_test= (np.exp(Y_test)-100)/1000\n        test_predict= (np.exp(test_predict)-100)/1000\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,Y_test, color='blue')\n        plt.plot( X_test['Year'].astype(str) + X_test['month'].astype(str) ,test_predict, color='red')\n        print ('rmse:',np.sqrt(mean_squared_error(Y_test, test_predict)))\n        print ('r2:', r2_score(Y_test, test_predict))\n        print ('mape:', mean_absolute_percentage_error(Y_test, test_predict))\n        #plt.show()\n        \nprint(\"rmsetrain:\",np.mean(train_rmse),\"rmsetest\",np.mean(test_rmse))\nprint (\"r2train:\",np.mean(train_r2),'r2test:',np.mean(test_r2) )\nprint ('mapetest:',np.mean(test_mape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(df.iloc[: , :-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True, axis=1)\n\ndf.replace([np.inf, -np.inf], np.nan, inplace=True)\ndf.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T14:47:47.880919Z","iopub.execute_input":"2024-11-02T14:47:47.882491Z","iopub.status.idle":"2024-11-02T14:47:48.263559Z","shell.execute_reply.started":"2024-11-02T14:47:47.882436Z","shell.execute_reply":"2024-11-02T14:47:48.262227Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# فرض بر این است که df دیتافریم اصلی شماست\nX = df.drop(columns=['Total_in'], axis=1)\ny = df['Total_in']\n\n# 2. Data Normalization\nscaler_X = MinMaxScaler(feature_range=(0, 1))\nscaler_y = MinMaxScaler(feature_range=(0, 1))\n\nX = scaler_X.fit_transform(X)\ny = scaler_y.fit_transform(y.values.reshape(-1, 1))  # Reshape y to be 2D\n\n# Define the number of time steps and reshape data\nn_steps = 15\nn_features = X.shape[1]\n\n# Reshape X and y into sequences for LSTM\nX_seq, y_seq = [], []\nfor i in range(len(X) - n_steps):\n    X_seq.append(X[i:i + n_steps, :])\n    y_seq.append(y[i + n_steps, 0])  # Adjust to get scalar values\n\nX_seq, y_seq = np.array(X_seq), np.array(y_seq)\n\n# 3. Define the LSTM model\ndef create_model():\n    model = Sequential()\n    model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n    model.add(Dropout(0.2))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\n# 4. TimeSeriesSplit Cross-Validation\ntscv = TimeSeriesSplit(n_splits=20)\nfold = 1\n\n# برای ذخیره R2 و RMSE هر فولد\nr2_scores = []\nrmse_scores = []\n\nfor train_index, test_index in tscv.split(X_seq):\n    print(f\"\\nTraining fold {fold}...\")\n\n    # Splitting data into train and validation sets\n    X_train, X_test = X_seq[train_index], X_seq[test_index]\n    y_train, y_test = y_seq[train_index], y_seq[test_index]\n\n    # Initialize the model\n    model = create_model()\n\n    # Train the model\n    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n\n    # Predictions on the test set\n    y_pred = model.predict(X_test)\n    \n    # Reshape y_pred and y_test to 1D arrays for metrics calculation\n    y_pred = y_pred.reshape(-1)\n    y_test = y_test.reshape(-1)\n    \n    # Calculate metrics\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    r2 = r2_score(y_test, y_pred)\n    \n    # Append metrics to lists\n    rmse_scores.append(rmse)\n    r2_scores.append(r2)\n\n    print(f\"Fold {fold} - RMSE: {rmse}\")\n    print(f\"Fold {fold} - R2: {r2}\")\n    \n    fold += 1\n\n# Print average metrics across all folds\nprint(\"\\nAverage RMSE across all folds:\", np.mean(rmse_scores))\nprint(\"Average R2 across all folds:\", np.mean(r2_scores))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T15:01:53.800909Z","iopub.execute_input":"2024-11-02T15:01:53.801369Z","iopub.status.idle":"2024-11-02T16:51:11.382690Z","shell.execute_reply.started":"2024-11-02T15:01:53.801334Z","shell.execute_reply":"2024-11-02T16:51:11.381238Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\nTraining fold 1...\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - loss: 27.5287 - val_loss: 0.0701\nEpoch 2/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 3.7602 - val_loss: 0.1090\nEpoch 3/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 1.0455 - val_loss: 0.0510\nEpoch 4/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4195 - val_loss: 0.0466\nEpoch 5/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.2553 - val_loss: 0.0323\nEpoch 6/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.1514 - val_loss: 0.0188\nEpoch 7/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.1323 - val_loss: 0.0214\nEpoch 8/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.1062 - val_loss: 0.0244\nEpoch 9/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0843 - val_loss: 0.0110\nEpoch 10/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0776 - val_loss: 0.0147\nEpoch 11/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0656 - val_loss: 0.0080\nEpoch 12/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0543 - val_loss: 0.0130\nEpoch 13/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0534 - val_loss: 0.0130\nEpoch 14/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0544 - val_loss: 0.0064\nEpoch 15/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0423 - val_loss: 0.0100\nEpoch 16/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0352 - val_loss: 0.0116\nEpoch 17/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0396 - val_loss: 0.0132\nEpoch 18/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0398 - val_loss: 0.0085\nEpoch 19/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0298 - val_loss: 0.0092\nEpoch 20/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0321 - val_loss: 0.0118\nEpoch 21/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0275 - val_loss: 0.0081\nEpoch 22/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0262 - val_loss: 0.0138\nEpoch 23/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0303 - val_loss: 0.0096\nEpoch 24/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0220 - val_loss: 0.0096\nEpoch 25/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0218 - val_loss: 0.0157\nEpoch 26/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0226 - val_loss: 0.0139\nEpoch 27/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0249 - val_loss: 0.0071\nEpoch 28/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0213 - val_loss: 0.0071\nEpoch 29/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0155 - val_loss: 0.0089\nEpoch 30/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0206 - val_loss: 0.0101\nEpoch 31/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0217 - val_loss: 0.0090\nEpoch 32/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0158 - val_loss: 0.0105\nEpoch 33/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0201 - val_loss: 0.0075\nEpoch 34/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0150 - val_loss: 0.0109\nEpoch 35/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0121 - val_loss: 0.0077\nEpoch 36/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0167 - val_loss: 0.0078\nEpoch 37/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0130 - val_loss: 0.0080\nEpoch 38/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0134 - val_loss: 0.0087\nEpoch 39/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0168 - val_loss: 0.0097\nEpoch 40/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0131 - val_loss: 0.0091\nEpoch 41/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0138 - val_loss: 0.0057\nEpoch 42/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0161 - val_loss: 0.0090\nEpoch 43/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0152 - val_loss: 0.0125\nEpoch 44/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0139 - val_loss: 0.0084\nEpoch 45/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0121 - val_loss: 0.0043\nEpoch 46/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0187 - val_loss: 0.0071\nEpoch 47/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0171 - val_loss: 0.0149\nEpoch 48/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0129 - val_loss: 0.0089\nEpoch 49/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0104 - val_loss: 0.0075\nEpoch 50/50\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0138 - val_loss: 0.0111\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\nFold 1 - RMSE: 0.10519668881345609\nFold 1 - R2: 0.7291636721146095\n\nTraining fold 2...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 7.0238 - val_loss: 0.0173\nEpoch 2/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0244 - val_loss: 0.0147\nEpoch 3/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0176 - val_loss: 0.0094\nEpoch 4/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0146 - val_loss: 0.0148\nEpoch 5/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0152 - val_loss: 0.0181\nEpoch 6/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0155 - val_loss: 0.0073\nEpoch 7/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0117 - val_loss: 0.0084\nEpoch 8/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0173 - val_loss: 0.0087\nEpoch 9/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0158 - val_loss: 0.0096\nEpoch 10/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0140 - val_loss: 0.0086\nEpoch 11/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0102 - val_loss: 0.0111\nEpoch 12/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0100 - val_loss: 0.0081\nEpoch 13/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0100 - val_loss: 0.0066\nEpoch 14/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0119 - val_loss: 0.0080\nEpoch 15/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0110 - val_loss: 0.0081\nEpoch 16/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0150 - val_loss: 0.0158\nEpoch 17/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0109 - val_loss: 0.0068\nEpoch 18/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0114 - val_loss: 0.0067\nEpoch 19/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0108 - val_loss: 0.0059\nEpoch 20/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0097 - val_loss: 0.0095\nEpoch 21/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0094 - val_loss: 0.0109\nEpoch 22/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0101 - val_loss: 0.0053\nEpoch 23/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0117 - val_loss: 0.0058\nEpoch 24/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0104 - val_loss: 0.0062\nEpoch 25/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0097 - val_loss: 0.0052\nEpoch 26/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0120 - val_loss: 0.0033\nEpoch 27/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0118 - val_loss: 0.0041\nEpoch 28/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0080 - val_loss: 0.0143\nEpoch 29/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0138 - val_loss: 0.0169\nEpoch 30/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0096 - val_loss: 0.0085\nEpoch 31/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0102 - val_loss: 0.0063\nEpoch 32/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0082 - val_loss: 0.0072\nEpoch 33/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0078 - val_loss: 0.0064\nEpoch 34/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0089 - val_loss: 0.0049\nEpoch 35/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0084 - val_loss: 0.0078\nEpoch 36/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0080 - val_loss: 0.0041\nEpoch 37/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0088 - val_loss: 0.0038\nEpoch 38/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0072 - val_loss: 0.0063\nEpoch 39/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0082 - val_loss: 0.0059\nEpoch 40/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0078 - val_loss: 0.0112\nEpoch 41/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0089 - val_loss: 0.0065\nEpoch 42/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0089 - val_loss: 0.0082\nEpoch 43/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0066 - val_loss: 0.0040\nEpoch 44/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0071 - val_loss: 0.0061\nEpoch 45/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0071 - val_loss: 0.0095\nEpoch 46/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0074 - val_loss: 0.0062\nEpoch 47/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0082 - val_loss: 0.0117\nEpoch 48/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0088 - val_loss: 0.0101\nEpoch 49/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0097 - val_loss: 0.0057\nEpoch 50/50\n\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0062 - val_loss: 0.0086\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\nFold 2 - RMSE: 0.09256713576642885\nFold 2 - R2: 0.7731008784663023\n\nTraining fold 3...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - loss: 5.3341 - val_loss: 0.0284\nEpoch 2/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.1120 - val_loss: 0.0293\nEpoch 3/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0413 - val_loss: 0.0210\nEpoch 4/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0289 - val_loss: 0.0194\nEpoch 5/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0240 - val_loss: 0.0173\nEpoch 6/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0208 - val_loss: 0.0160\nEpoch 7/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0154 - val_loss: 0.0152\nEpoch 8/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0165 - val_loss: 0.0136\nEpoch 9/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0159 - val_loss: 0.0133\nEpoch 10/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0190 - val_loss: 0.0120\nEpoch 11/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0128 - val_loss: 0.0130\nEpoch 12/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0143 - val_loss: 0.0125\nEpoch 13/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0156 - val_loss: 0.0138\nEpoch 14/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0133 - val_loss: 0.0125\nEpoch 15/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0123 - val_loss: 0.0112\nEpoch 16/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0112 - val_loss: 0.0108\nEpoch 17/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0104 - val_loss: 0.0102\nEpoch 18/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0132 - val_loss: 0.0164\nEpoch 19/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0121 - val_loss: 0.0126\nEpoch 20/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0103 - val_loss: 0.0137\nEpoch 21/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0114 - val_loss: 0.0092\nEpoch 22/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0111 - val_loss: 0.0125\nEpoch 23/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0133 - val_loss: 0.0131\nEpoch 24/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0126 - val_loss: 0.0105\nEpoch 25/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0099 - val_loss: 0.0112\nEpoch 26/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0107 - val_loss: 0.0106\nEpoch 27/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0099 - val_loss: 0.0125\nEpoch 28/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0084 - val_loss: 0.0118\nEpoch 29/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0085 - val_loss: 0.0090\nEpoch 30/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0097 - val_loss: 0.0096\nEpoch 31/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0088 - val_loss: 0.0122\nEpoch 32/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0090 - val_loss: 0.0115\nEpoch 33/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0095 - val_loss: 0.0069\nEpoch 34/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0076 - val_loss: 0.0072\nEpoch 35/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0082 - val_loss: 0.0068\nEpoch 36/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0086 - val_loss: 0.0083\nEpoch 37/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0069 - val_loss: 0.0138\nEpoch 38/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0072 - val_loss: 0.0079\nEpoch 39/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0076 - val_loss: 0.0096\nEpoch 40/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0077 - val_loss: 0.0082\nEpoch 41/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0075 - val_loss: 0.0086\nEpoch 42/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0070 - val_loss: 0.0047\nEpoch 43/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0076 - val_loss: 0.0070\nEpoch 44/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0088 - val_loss: 0.0075\nEpoch 45/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0067 - val_loss: 0.0037\nEpoch 46/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0078 - val_loss: 0.0067\nEpoch 47/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0063 - val_loss: 0.0088\nEpoch 48/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0053 - val_loss: 0.0055\nEpoch 49/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 0.0067 - val_loss: 0.0041\nEpoch 50/50\n\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0057 - val_loss: 0.0053\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\nFold 3 - RMSE: 0.07289542017305634\nFold 3 - R2: 0.8828251242262486\n\nTraining fold 4...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 1.8312 - val_loss: 0.0094\nEpoch 2/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0253 - val_loss: 0.0057\nEpoch 3/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0180 - val_loss: 0.0077\nEpoch 4/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0175 - val_loss: 0.0056\nEpoch 5/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0166 - val_loss: 0.0057\nEpoch 6/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0166 - val_loss: 0.0047\nEpoch 7/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0138 - val_loss: 0.0054\nEpoch 8/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0141 - val_loss: 0.0063\nEpoch 9/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0150 - val_loss: 0.0070\nEpoch 10/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0150 - val_loss: 0.0075\nEpoch 11/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0140 - val_loss: 0.0059\nEpoch 12/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0115 - val_loss: 0.0039\nEpoch 13/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0119 - val_loss: 0.0037\nEpoch 14/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0114 - val_loss: 0.0048\nEpoch 15/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0092 - val_loss: 0.0040\nEpoch 16/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0117 - val_loss: 0.0042\nEpoch 17/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0115 - val_loss: 0.0073\nEpoch 18/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0099 - val_loss: 0.0106\nEpoch 19/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0092 - val_loss: 0.0037\nEpoch 20/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0116 - val_loss: 0.0078\nEpoch 21/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0077 - val_loss: 0.0058\nEpoch 22/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0076 - val_loss: 0.0045\nEpoch 23/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0075 - val_loss: 0.0053\nEpoch 24/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0070 - val_loss: 0.0047\nEpoch 25/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0079 - val_loss: 0.0052\nEpoch 26/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0083 - val_loss: 0.0042\nEpoch 27/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0071 - val_loss: 0.0043\nEpoch 28/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0081 - val_loss: 0.0064\nEpoch 29/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0080 - val_loss: 0.0046\nEpoch 30/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0063 - val_loss: 0.0070\nEpoch 31/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0071\nEpoch 32/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0064 - val_loss: 0.0076\nEpoch 33/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0061 - val_loss: 0.0046\nEpoch 34/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0076 - val_loss: 0.0081\nEpoch 35/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 0.0058 - val_loss: 0.0054\nEpoch 36/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0063 - val_loss: 0.0069\nEpoch 37/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0070 - val_loss: 0.0083\nEpoch 38/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0061 - val_loss: 0.0056\nEpoch 39/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0054 - val_loss: 0.0063\nEpoch 40/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0044 - val_loss: 0.0075\nEpoch 41/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0048 - val_loss: 0.0067\nEpoch 42/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0052 - val_loss: 0.0058\nEpoch 43/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0079\nEpoch 44/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0056\nEpoch 45/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0058 - val_loss: 0.0087\nEpoch 46/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0040 - val_loss: 0.0059\nEpoch 47/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0041 - val_loss: 0.0052\nEpoch 48/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0051 - val_loss: 0.0056\nEpoch 49/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0045 - val_loss: 0.0060\nEpoch 50/50\n\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0036 - val_loss: 0.0091\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\nFold 4 - RMSE: 0.09533585500901744\nFold 4 - R2: 0.6116194071460183\n\nTraining fold 5...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 6.8928 - val_loss: 0.0245\nEpoch 2/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0356 - val_loss: 0.0043\nEpoch 3/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0215 - val_loss: 0.0067\nEpoch 4/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0201 - val_loss: 0.0059\nEpoch 5/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0126 - val_loss: 0.0048\nEpoch 6/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0125 - val_loss: 0.0045\nEpoch 7/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0106 - val_loss: 0.0043\nEpoch 8/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0137 - val_loss: 0.0052\nEpoch 9/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0111 - val_loss: 0.0035\nEpoch 10/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0107 - val_loss: 0.0035\nEpoch 11/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0105 - val_loss: 0.0035\nEpoch 12/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0125 - val_loss: 0.0034\nEpoch 13/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0086 - val_loss: 0.0039\nEpoch 14/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0088 - val_loss: 0.0038\nEpoch 15/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0088 - val_loss: 0.0035\nEpoch 16/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0087 - val_loss: 0.0040\nEpoch 17/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0085 - val_loss: 0.0035\nEpoch 18/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0088 - val_loss: 0.0041\nEpoch 19/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0085 - val_loss: 0.0034\nEpoch 20/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0082 - val_loss: 0.0027\nEpoch 21/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0045\nEpoch 22/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0074 - val_loss: 0.0044\nEpoch 23/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0075 - val_loss: 0.0040\nEpoch 24/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0072 - val_loss: 0.0031\nEpoch 25/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0073 - val_loss: 0.0031\nEpoch 26/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0067 - val_loss: 0.0050\nEpoch 27/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0066 - val_loss: 0.0031\nEpoch 28/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0030\nEpoch 29/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0057 - val_loss: 0.0029\nEpoch 30/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0062 - val_loss: 0.0033\nEpoch 31/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0034\nEpoch 32/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0053 - val_loss: 0.0033\nEpoch 33/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0055 - val_loss: 0.0036\nEpoch 34/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0059 - val_loss: 0.0053\nEpoch 35/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0064 - val_loss: 0.0035\nEpoch 36/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0068 - val_loss: 0.0039\nEpoch 37/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0052\nEpoch 38/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0034\nEpoch 39/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0031\nEpoch 40/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0057 - val_loss: 0.0046\nEpoch 41/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0053 - val_loss: 0.0032\nEpoch 42/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0049\nEpoch 43/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0033\nEpoch 44/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0049 - val_loss: 0.0038\nEpoch 45/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0034\nEpoch 46/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0036\nEpoch 47/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0037\nEpoch 48/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0045 - val_loss: 0.0039\nEpoch 49/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0043 - val_loss: 0.0042\nEpoch 50/50\n\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0043 - val_loss: 0.0056\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 5 - RMSE: 0.07455076077949464\nFold 5 - R2: 0.8137801323988041\n\nTraining fold 6...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 7.9966 - val_loss: 0.0261\nEpoch 2/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0435 - val_loss: 0.0102\nEpoch 3/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0292 - val_loss: 0.0092\nEpoch 4/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0243 - val_loss: 0.0087\nEpoch 5/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0224 - val_loss: 0.0127\nEpoch 6/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0185 - val_loss: 0.0108\nEpoch 7/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0191 - val_loss: 0.0063\nEpoch 8/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0238 - val_loss: 0.0094\nEpoch 9/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0254 - val_loss: 0.0064\nEpoch 10/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0164 - val_loss: 0.0070\nEpoch 11/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0172 - val_loss: 0.0058\nEpoch 12/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0176 - val_loss: 0.0071\nEpoch 13/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0181 - val_loss: 0.0072\nEpoch 14/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0160 - val_loss: 0.0053\nEpoch 15/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0180 - val_loss: 0.0067\nEpoch 16/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0127 - val_loss: 0.0084\nEpoch 17/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0145 - val_loss: 0.0062\nEpoch 18/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0128 - val_loss: 0.0058\nEpoch 19/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0148 - val_loss: 0.0074\nEpoch 20/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0139 - val_loss: 0.0052\nEpoch 21/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0138 - val_loss: 0.0053\nEpoch 22/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0138 - val_loss: 0.0059\nEpoch 23/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0110 - val_loss: 0.0057\nEpoch 24/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0108 - val_loss: 0.0037\nEpoch 25/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0078 - val_loss: 0.0058\nEpoch 26/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0089 - val_loss: 0.0052\nEpoch 27/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0077 - val_loss: 0.0101\nEpoch 28/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0092 - val_loss: 0.0038\nEpoch 29/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0082 - val_loss: 0.0035\nEpoch 30/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0085 - val_loss: 0.0034\nEpoch 31/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0085 - val_loss: 0.0034\nEpoch 32/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0062 - val_loss: 0.0042\nEpoch 33/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0070 - val_loss: 0.0040\nEpoch 34/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0070 - val_loss: 0.0047\nEpoch 35/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0072 - val_loss: 0.0056\nEpoch 36/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0063 - val_loss: 0.0036\nEpoch 37/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0065 - val_loss: 0.0042\nEpoch 38/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0032\nEpoch 39/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0068 - val_loss: 0.0059\nEpoch 40/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0073 - val_loss: 0.0046\nEpoch 41/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0070 - val_loss: 0.0037\nEpoch 42/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0059 - val_loss: 0.0031\nEpoch 43/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0044\nEpoch 44/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0068 - val_loss: 0.0036\nEpoch 45/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0063 - val_loss: 0.0036\nEpoch 46/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0050 - val_loss: 0.0031\nEpoch 47/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0053 - val_loss: 0.0042\nEpoch 48/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0062 - val_loss: 0.0035\nEpoch 49/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0049\nEpoch 50/50\n\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0048 - val_loss: 0.0033\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 6 - RMSE: 0.057096358543665654\nFold 6 - R2: 0.885329671704082\n\nTraining fold 7...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 6.1769 - val_loss: 0.0104\nEpoch 2/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0437 - val_loss: 0.0061\nEpoch 3/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0183 - val_loss: 0.0052\nEpoch 4/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0135 - val_loss: 0.0044\nEpoch 5/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0121 - val_loss: 0.0039\nEpoch 6/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0105 - val_loss: 0.0040\nEpoch 7/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0099 - val_loss: 0.0032\nEpoch 8/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0092 - val_loss: 0.0032\nEpoch 9/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0083 - val_loss: 0.0032\nEpoch 10/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0082 - val_loss: 0.0036\nEpoch 11/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0085 - val_loss: 0.0042\nEpoch 12/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0074 - val_loss: 0.0040\nEpoch 13/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0075 - val_loss: 0.0032\nEpoch 14/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0061 - val_loss: 0.0033\nEpoch 15/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 0.0059 - val_loss: 0.0031\nEpoch 16/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0055 - val_loss: 0.0033\nEpoch 17/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0056 - val_loss: 0.0036\nEpoch 18/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0058 - val_loss: 0.0034\nEpoch 19/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0055 - val_loss: 0.0034\nEpoch 20/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0052 - val_loss: 0.0034\nEpoch 21/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0049 - val_loss: 0.0029\nEpoch 22/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0032\nEpoch 23/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0039\nEpoch 24/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0050 - val_loss: 0.0029\nEpoch 25/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0028\nEpoch 26/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0042\nEpoch 27/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0047 - val_loss: 0.0033\nEpoch 28/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0032\nEpoch 29/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0030\nEpoch 30/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0036 - val_loss: 0.0036\nEpoch 31/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0039 - val_loss: 0.0034\nEpoch 32/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0029\nEpoch 33/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0041 - val_loss: 0.0030\nEpoch 34/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0029\nEpoch 35/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0030\nEpoch 36/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0035\nEpoch 37/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0030\nEpoch 38/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0032\nEpoch 39/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0035\nEpoch 40/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0035 - val_loss: 0.0029\nEpoch 41/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0032 - val_loss: 0.0039\nEpoch 42/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0033\nEpoch 43/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0028\nEpoch 44/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0029\nEpoch 45/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0040\nEpoch 46/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0034 - val_loss: 0.0040\nEpoch 47/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0031 - val_loss: 0.0029\nEpoch 48/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0034\nEpoch 49/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0029\nEpoch 50/50\n\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0030\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\nFold 7 - RMSE: 0.05466941075342496\nFold 7 - R2: 0.9287904239315744\n\nTraining fold 8...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.3030 - val_loss: 0.0155\nEpoch 2/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0299 - val_loss: 0.0157\nEpoch 3/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0236 - val_loss: 0.0160\nEpoch 4/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0204 - val_loss: 0.0093\nEpoch 5/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0149 - val_loss: 0.0114\nEpoch 6/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0133 - val_loss: 0.0106\nEpoch 7/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0105 - val_loss: 0.0100\nEpoch 8/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0117 - val_loss: 0.0107\nEpoch 9/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0112 - val_loss: 0.0099\nEpoch 10/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0092 - val_loss: 0.0101\nEpoch 11/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0088 - val_loss: 0.0121\nEpoch 12/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0099 - val_loss: 0.0085\nEpoch 13/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0092 - val_loss: 0.0086\nEpoch 14/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0082 - val_loss: 0.0090\nEpoch 15/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0065 - val_loss: 0.0086\nEpoch 16/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0077 - val_loss: 0.0084\nEpoch 17/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 18/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0065 - val_loss: 0.0075\nEpoch 19/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0063 - val_loss: 0.0072\nEpoch 20/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0073\nEpoch 21/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0070\nEpoch 22/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0052 - val_loss: 0.0061\nEpoch 23/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0052 - val_loss: 0.0063\nEpoch 24/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0064\nEpoch 25/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0059 - val_loss: 0.0068\nEpoch 26/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0054 - val_loss: 0.0062\nEpoch 27/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0056 - val_loss: 0.0060\nEpoch 28/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0057 - val_loss: 0.0069\nEpoch 29/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0061 - val_loss: 0.0068\nEpoch 30/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0059 - val_loss: 0.0065\nEpoch 31/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0065\nEpoch 32/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0064\nEpoch 33/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 0.0053 - val_loss: 0.0093\nEpoch 34/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0058 - val_loss: 0.0064\nEpoch 35/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0046 - val_loss: 0.0069\nEpoch 36/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0051 - val_loss: 0.0062\nEpoch 37/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0051 - val_loss: 0.0060\nEpoch 38/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0064\nEpoch 39/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 0.0056 - val_loss: 0.0057\nEpoch 40/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0048 - val_loss: 0.0066\nEpoch 41/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0049 - val_loss: 0.0056\nEpoch 42/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0053 - val_loss: 0.0055\nEpoch 43/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0051 - val_loss: 0.0062\nEpoch 44/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0058 - val_loss: 0.0081\nEpoch 45/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0058 - val_loss: 0.0053\nEpoch 46/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0052 - val_loss: 0.0067\nEpoch 47/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0056 - val_loss: 0.0058\nEpoch 48/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0050 - val_loss: 0.0062\nEpoch 49/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0054\nEpoch 50/50\n\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0055\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\nFold 8 - RMSE: 0.07445685236960893\nFold 8 - R2: 0.838660572532572\n\nTraining fold 9...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 1.2625 - val_loss: 0.0033\nEpoch 2/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0150 - val_loss: 0.0052\nEpoch 3/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0136 - val_loss: 0.0032\nEpoch 4/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0111 - val_loss: 0.0022\nEpoch 5/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0108 - val_loss: 0.0029\nEpoch 6/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0104 - val_loss: 0.0024\nEpoch 7/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - loss: 0.0094 - val_loss: 0.0024\nEpoch 8/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0097 - val_loss: 0.0027\nEpoch 9/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0085 - val_loss: 0.0028\nEpoch 10/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0076 - val_loss: 0.0023\nEpoch 11/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0094 - val_loss: 0.0019\nEpoch 12/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0075 - val_loss: 0.0017\nEpoch 13/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0076 - val_loss: 0.0017\nEpoch 14/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0073 - val_loss: 0.0021\nEpoch 15/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0074 - val_loss: 0.0032\nEpoch 16/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0064 - val_loss: 0.0021\nEpoch 17/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0063 - val_loss: 0.0016\nEpoch 18/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0068 - val_loss: 0.0017\nEpoch 19/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0063 - val_loss: 0.0022\nEpoch 20/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0065 - val_loss: 0.0016\nEpoch 21/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0058 - val_loss: 0.0028\nEpoch 22/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0019\nEpoch 23/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0064 - val_loss: 0.0015\nEpoch 24/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0051 - val_loss: 0.0015\nEpoch 25/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0051 - val_loss: 0.0014\nEpoch 26/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 0.0049 - val_loss: 0.0014\nEpoch 27/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0052 - val_loss: 0.0015\nEpoch 28/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0025\nEpoch 29/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0044 - val_loss: 0.0014\nEpoch 30/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0046 - val_loss: 0.0017\nEpoch 31/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0048 - val_loss: 0.0020\nEpoch 32/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0014\nEpoch 33/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0015\nEpoch 34/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0043 - val_loss: 0.0018\nEpoch 35/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0042 - val_loss: 0.0014\nEpoch 36/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0047 - val_loss: 0.0015\nEpoch 37/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0044 - val_loss: 0.0017\nEpoch 38/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0038 - val_loss: 0.0020\nEpoch 39/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0016\nEpoch 40/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0042 - val_loss: 0.0016\nEpoch 41/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0045 - val_loss: 0.0015\nEpoch 42/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0044 - val_loss: 0.0013\nEpoch 43/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0044 - val_loss: 0.0015\nEpoch 44/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0045 - val_loss: 0.0017\nEpoch 45/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0015\nEpoch 46/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0038 - val_loss: 0.0015\nEpoch 47/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0037 - val_loss: 0.0017\nEpoch 48/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0020\nEpoch 49/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0017\nEpoch 50/50\n\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0037 - val_loss: 0.0016\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 9 - RMSE: 0.040215176340588556\nFold 9 - R2: 0.9003855897768984\n\nTraining fold 10...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 4.4617 - val_loss: 0.0186\nEpoch 2/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0508 - val_loss: 0.0159\nEpoch 3/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0456 - val_loss: 0.0112\nEpoch 4/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0437 - val_loss: 0.0087\nEpoch 5/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0420 - val_loss: 0.0107\nEpoch 6/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0380 - val_loss: 0.0052\nEpoch 7/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0241 - val_loss: 0.0050\nEpoch 8/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0191 - val_loss: 0.0020\nEpoch 9/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0170 - val_loss: 0.0023\nEpoch 10/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0149 - val_loss: 0.0059\nEpoch 11/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0150 - val_loss: 0.0049\nEpoch 12/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0163 - val_loss: 0.0020\nEpoch 13/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0157 - val_loss: 0.0063\nEpoch 14/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0127 - val_loss: 0.0131\nEpoch 15/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0125 - val_loss: 0.0074\nEpoch 16/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0111 - val_loss: 0.0163\nEpoch 17/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0113 - val_loss: 0.0035\nEpoch 18/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0116 - val_loss: 0.0102\nEpoch 19/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0104 - val_loss: 0.0024\nEpoch 20/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0101 - val_loss: 0.0067\nEpoch 21/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0088 - val_loss: 0.0085\nEpoch 22/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0095 - val_loss: 0.0014\nEpoch 23/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0100 - val_loss: 0.0057\nEpoch 24/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0093 - val_loss: 0.0058\nEpoch 25/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0086 - val_loss: 0.0043\nEpoch 26/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0036\nEpoch 27/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0081 - val_loss: 0.0021\nEpoch 28/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0081 - val_loss: 0.0091\nEpoch 29/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0064 - val_loss: 0.0062\nEpoch 30/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0083 - val_loss: 0.0014\nEpoch 31/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0070 - val_loss: 0.0056\nEpoch 32/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0066 - val_loss: 0.0078\nEpoch 33/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0072 - val_loss: 0.0069\nEpoch 34/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0066 - val_loss: 0.0064\nEpoch 35/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0063 - val_loss: 0.0031\nEpoch 36/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0058 - val_loss: 0.0058\nEpoch 37/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0056 - val_loss: 0.0034\nEpoch 38/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0054 - val_loss: 0.0044\nEpoch 39/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0088\nEpoch 40/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0065 - val_loss: 0.0081\nEpoch 41/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0080\nEpoch 42/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0050 - val_loss: 0.0047\nEpoch 43/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0049 - val_loss: 0.0030\nEpoch 44/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0055 - val_loss: 0.0055\nEpoch 45/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0050\nEpoch 46/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0089\nEpoch 47/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0059 - val_loss: 0.0085\nEpoch 48/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0049 - val_loss: 0.0032\nEpoch 49/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0093\nEpoch 50/50\n\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0117\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\nFold 10 - RMSE: 0.10832818482049938\nFold 10 - R2: 0.28001749425948697\n\nTraining fold 11...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 0.7308 - val_loss: 0.0069\nEpoch 2/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0181 - val_loss: 0.0050\nEpoch 3/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0141 - val_loss: 0.0051\nEpoch 4/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0112 - val_loss: 0.0047\nEpoch 5/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 0.0109 - val_loss: 0.0055\nEpoch 6/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0083 - val_loss: 0.0044\nEpoch 7/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0080 - val_loss: 0.0045\nEpoch 8/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0078 - val_loss: 0.0042\nEpoch 9/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0067 - val_loss: 0.0054\nEpoch 10/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0061 - val_loss: 0.0062\nEpoch 11/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0058 - val_loss: 0.0049\nEpoch 12/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0055 - val_loss: 0.0051\nEpoch 13/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0051 - val_loss: 0.0046\nEpoch 14/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0051\nEpoch 15/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0044\nEpoch 16/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0039\nEpoch 17/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0046\nEpoch 18/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0040 - val_loss: 0.0040\nEpoch 19/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0043 - val_loss: 0.0041\nEpoch 20/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0047\nEpoch 21/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.0044\nEpoch 22/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0039 - val_loss: 0.0032\nEpoch 23/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0039\nEpoch 24/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0049\nEpoch 25/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 0.0036 - val_loss: 0.0054\nEpoch 26/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0035\nEpoch 27/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0033 - val_loss: 0.0029\nEpoch 28/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0039 - val_loss: 0.0032\nEpoch 29/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0037 - val_loss: 0.0033\nEpoch 30/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0039 - val_loss: 0.0030\nEpoch 31/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0034 - val_loss: 0.0023\nEpoch 32/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0034 - val_loss: 0.0035\nEpoch 33/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0034 - val_loss: 0.0029\nEpoch 34/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0034 - val_loss: 0.0029\nEpoch 35/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 0.0031 - val_loss: 0.0029\nEpoch 36/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 0.0031 - val_loss: 0.0046\nEpoch 37/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0029\nEpoch 38/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0036 - val_loss: 0.0039\nEpoch 39/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0033 - val_loss: 0.0048\nEpoch 40/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0032 - val_loss: 0.0043\nEpoch 41/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0037 - val_loss: 0.0021\nEpoch 42/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0031 - val_loss: 0.0037\nEpoch 43/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0030 - val_loss: 0.0029\nEpoch 44/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0036 - val_loss: 0.0030\nEpoch 45/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0037\nEpoch 46/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0033 - val_loss: 0.0023\nEpoch 47/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0067\nEpoch 48/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0035 - val_loss: 0.0040\nEpoch 49/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0032 - val_loss: 0.0039\nEpoch 50/50\n\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 0.0032 - val_loss: 0.0029\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 11 - RMSE: 0.05396386923186658\nFold 11 - R2: 0.9146231070427975\n\nTraining fold 12...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 0.5012 - val_loss: 0.0050\nEpoch 2/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0162 - val_loss: 0.0060\nEpoch 3/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0127 - val_loss: 0.0041\nEpoch 4/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0109 - val_loss: 0.0044\nEpoch 5/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0102 - val_loss: 0.0033\nEpoch 6/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0092 - val_loss: 0.0092\nEpoch 7/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0096 - val_loss: 0.0033\nEpoch 8/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0084 - val_loss: 0.0057\nEpoch 9/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0076 - val_loss: 0.0046\nEpoch 10/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0070 - val_loss: 0.0071\nEpoch 11/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 0.0132\nEpoch 12/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0079 - val_loss: 0.0029\nEpoch 13/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0070 - val_loss: 0.0054\nEpoch 14/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0124\nEpoch 15/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0070 - val_loss: 0.0056\nEpoch 16/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0071 - val_loss: 0.0040\nEpoch 17/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0040\nEpoch 18/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0069 - val_loss: 0.0069\nEpoch 19/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 0.0063 - val_loss: 0.0064\nEpoch 20/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0071 - val_loss: 0.0049\nEpoch 21/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0067 - val_loss: 0.0044\nEpoch 22/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0062 - val_loss: 0.0041\nEpoch 23/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0064 - val_loss: 0.0073\nEpoch 24/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0067 - val_loss: 0.0032\nEpoch 25/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0067 - val_loss: 0.0023\nEpoch 26/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0055 - val_loss: 0.0054\nEpoch 27/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0052 - val_loss: 0.0044\nEpoch 28/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0055 - val_loss: 0.0036\nEpoch 29/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0050 - val_loss: 0.0037\nEpoch 30/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0036\nEpoch 31/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0051 - val_loss: 0.0091\nEpoch 32/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0059 - val_loss: 0.0046\nEpoch 33/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0054 - val_loss: 0.0050\nEpoch 34/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0051\nEpoch 35/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0046 - val_loss: 0.0058\nEpoch 36/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0051\nEpoch 37/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0045 - val_loss: 0.0039\nEpoch 38/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0045 - val_loss: 0.0044\nEpoch 39/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0053 - val_loss: 0.0034\nEpoch 40/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0047 - val_loss: 0.0040\nEpoch 41/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0041 - val_loss: 0.0037\nEpoch 42/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0048 - val_loss: 0.0038\nEpoch 43/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0033\nEpoch 44/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0023\nEpoch 45/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0051 - val_loss: 0.0030\nEpoch 46/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0036\nEpoch 47/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0023\nEpoch 48/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0035\nEpoch 49/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0055 - val_loss: 0.0027\nEpoch 50/50\n\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0049 - val_loss: 0.0037\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\nFold 12 - RMSE: 0.06084096933304001\nFold 12 - R2: 0.8827123104480589\n\nTraining fold 13...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.8678 - val_loss: 0.0041\nEpoch 2/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0119 - val_loss: 0.0037\nEpoch 3/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0113 - val_loss: 0.0032\nEpoch 4/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0095 - val_loss: 0.0042\nEpoch 5/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0089 - val_loss: 0.0047\nEpoch 6/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0093 - val_loss: 0.0050\nEpoch 7/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0074 - val_loss: 0.0024\nEpoch 8/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0069 - val_loss: 0.0029\nEpoch 9/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0065 - val_loss: 0.0023\nEpoch 10/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0078 - val_loss: 0.0037\nEpoch 11/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0068 - val_loss: 0.0026\nEpoch 12/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0073 - val_loss: 0.0034\nEpoch 13/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0079 - val_loss: 0.0032\nEpoch 14/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0066 - val_loss: 0.0038\nEpoch 15/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0065 - val_loss: 0.0031\nEpoch 16/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 0.0068 - val_loss: 0.0028\nEpoch 17/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0062 - val_loss: 0.0040\nEpoch 18/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0062 - val_loss: 0.0069\nEpoch 19/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0074 - val_loss: 0.0030\nEpoch 20/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0069 - val_loss: 0.0050\nEpoch 21/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0049 - val_loss: 0.0025\nEpoch 22/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0046 - val_loss: 0.0024\nEpoch 23/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0053 - val_loss: 0.0027\nEpoch 24/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0046 - val_loss: 0.0030\nEpoch 25/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - loss: 0.0049 - val_loss: 0.0030\nEpoch 26/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0059 - val_loss: 0.0024\nEpoch 27/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0049 - val_loss: 0.0026\nEpoch 28/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - loss: 0.0047 - val_loss: 0.0052\nEpoch 29/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0050 - val_loss: 0.0031\nEpoch 30/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0044 - val_loss: 0.0023\nEpoch 31/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0025\nEpoch 32/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0041 - val_loss: 0.0024\nEpoch 33/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0043 - val_loss: 0.0028\nEpoch 34/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0047 - val_loss: 0.0034\nEpoch 35/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0047\nEpoch 36/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0060 - val_loss: 0.0030\nEpoch 37/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0042 - val_loss: 0.0032\nEpoch 38/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - loss: 0.0044 - val_loss: 0.0033\nEpoch 39/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0046 - val_loss: 0.0029\nEpoch 40/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0042 - val_loss: 0.0025\nEpoch 41/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0049 - val_loss: 0.0037\nEpoch 42/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0057 - val_loss: 0.0036\nEpoch 43/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 0.0043 - val_loss: 0.0023\nEpoch 44/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0046 - val_loss: 0.0028\nEpoch 45/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0042 - val_loss: 0.0025\nEpoch 46/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0041 - val_loss: 0.0027\nEpoch 47/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - loss: 0.0044 - val_loss: 0.0037\nEpoch 48/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0048 - val_loss: 0.0032\nEpoch 49/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0046 - val_loss: 0.0026\nEpoch 50/50\n\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0046 - val_loss: 0.0024\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 13 - RMSE: 0.0488954422351696\nFold 13 - R2: 0.9318391721064202\n\nTraining fold 14...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 1.2019 - val_loss: 0.0037\nEpoch 2/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 0.0128 - val_loss: 0.0030\nEpoch 3/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0104 - val_loss: 0.0071\nEpoch 4/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0093 - val_loss: 0.0035\nEpoch 5/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0084 - val_loss: 0.0022\nEpoch 6/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 0.0082 - val_loss: 0.0049\nEpoch 7/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0074 - val_loss: 0.0026\nEpoch 8/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0072 - val_loss: 0.0029\nEpoch 9/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 0.0072 - val_loss: 0.0029\nEpoch 10/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 0.0055 - val_loss: 0.0023\nEpoch 11/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0060 - val_loss: 0.0026\nEpoch 12/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0028\nEpoch 13/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.0056 - val_loss: 0.0027\nEpoch 14/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0057 - val_loss: 0.0031\nEpoch 15/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0038\nEpoch 16/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0035\nEpoch 17/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0052 - val_loss: 0.0030\nEpoch 18/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0054 - val_loss: 0.0031\nEpoch 19/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0034\nEpoch 20/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0049 - val_loss: 0.0047\nEpoch 21/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0034\nEpoch 22/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0038\nEpoch 23/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0033\nEpoch 24/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.0046 - val_loss: 0.0037\nEpoch 25/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0050 - val_loss: 0.0039\nEpoch 26/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0049 - val_loss: 0.0031\nEpoch 27/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0050 - val_loss: 0.0032\nEpoch 28/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0047 - val_loss: 0.0031\nEpoch 29/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0031\nEpoch 30/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0052 - val_loss: 0.0030\nEpoch 31/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0048 - val_loss: 0.0036\nEpoch 32/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0031\nEpoch 33/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0032\nEpoch 34/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0033\nEpoch 35/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0048 - val_loss: 0.0032\nEpoch 36/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0038\nEpoch 37/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 0.0048 - val_loss: 0.0042\nEpoch 38/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0052 - val_loss: 0.0033\nEpoch 39/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0036\nEpoch 40/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0047\nEpoch 41/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0049 - val_loss: 0.0040\nEpoch 42/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0049 - val_loss: 0.0033\nEpoch 43/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0048 - val_loss: 0.0033\nEpoch 44/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0048 - val_loss: 0.0041\nEpoch 45/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0047 - val_loss: 0.0050\nEpoch 46/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 0.0050 - val_loss: 0.0031\nEpoch 47/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0047 - val_loss: 0.0039\nEpoch 48/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0034\nEpoch 49/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0051 - val_loss: 0.0039\nEpoch 50/50\n\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0031\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 14 - RMSE: 0.055519855167901026\nFold 14 - R2: 0.9042268533240646\n\nTraining fold 15...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 1.0411 - val_loss: 0.0104\nEpoch 2/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0226 - val_loss: 0.0060\nEpoch 3/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 0.0206 - val_loss: 0.0051\nEpoch 4/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0164 - val_loss: 0.0038\nEpoch 5/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0151 - val_loss: 0.0044\nEpoch 6/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0133 - val_loss: 0.0046\nEpoch 7/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 0.0118 - val_loss: 0.0038\nEpoch 8/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.0104 - val_loss: 0.0031\nEpoch 9/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0090 - val_loss: 0.0029\nEpoch 10/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0081 - val_loss: 0.0031\nEpoch 11/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0079 - val_loss: 0.0032\nEpoch 12/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0066 - val_loss: 0.0025\nEpoch 13/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 0.0060 - val_loss: 0.0025\nEpoch 14/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0021\nEpoch 15/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.0057 - val_loss: 0.0023\nEpoch 16/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0048 - val_loss: 0.0023\nEpoch 17/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0048 - val_loss: 0.0020\nEpoch 18/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - loss: 0.0041 - val_loss: 0.0020\nEpoch 19/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0040 - val_loss: 0.0021\nEpoch 20/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 0.0042 - val_loss: 0.0019\nEpoch 21/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0021\nEpoch 22/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0019\nEpoch 23/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0036 - val_loss: 0.0020\nEpoch 24/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - loss: 0.0036 - val_loss: 0.0021\nEpoch 25/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.0035 - val_loss: 0.0024\nEpoch 26/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0032 - val_loss: 0.0019\nEpoch 27/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0035 - val_loss: 0.0019\nEpoch 28/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - loss: 0.0035 - val_loss: 0.0019\nEpoch 29/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 30/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 0.0034 - val_loss: 0.0047\nEpoch 31/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0040 - val_loss: 0.0018\nEpoch 32/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0033 - val_loss: 0.0018\nEpoch 33/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0037 - val_loss: 0.0017\nEpoch 34/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0017\nEpoch 35/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0023\nEpoch 36/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0031\nEpoch 37/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 38/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0037 - val_loss: 0.0023\nEpoch 39/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 0.0033 - val_loss: 0.0022\nEpoch 40/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0031 - val_loss: 0.0024\nEpoch 41/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0017\nEpoch 42/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0019\nEpoch 43/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - loss: 0.0035 - val_loss: 0.0023\nEpoch 44/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 45/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.0035 - val_loss: 0.0023\nEpoch 46/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 0.0032 - val_loss: 0.0018\nEpoch 47/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 0.0035 - val_loss: 0.0032\nEpoch 48/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - loss: 0.0037 - val_loss: 0.0015\nEpoch 49/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0021\nEpoch 50/50\n\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0024\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\nFold 15 - RMSE: 0.048478988553279284\nFold 15 - R2: 0.8709033589884363\n\nTraining fold 16...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 0.8390 - val_loss: 0.0206\nEpoch 2/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 0.0244 - val_loss: 0.0236\nEpoch 3/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0210 - val_loss: 0.0291\nEpoch 4/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0184 - val_loss: 0.0220\nEpoch 5/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0148 - val_loss: 0.0113\nEpoch 6/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0130 - val_loss: 0.0108\nEpoch 7/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0113 - val_loss: 0.0155\nEpoch 8/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0103 - val_loss: 0.0068\nEpoch 9/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0090 - val_loss: 0.0100\nEpoch 10/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0084 - val_loss: 0.0101\nEpoch 11/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0083 - val_loss: 0.0071\nEpoch 12/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0078 - val_loss: 0.0046\nEpoch 13/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0081 - val_loss: 0.0061\nEpoch 14/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0072 - val_loss: 0.0095\nEpoch 15/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0074\nEpoch 16/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - loss: 0.0067 - val_loss: 0.0095\nEpoch 17/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0073 - val_loss: 0.0069\nEpoch 18/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0063 - val_loss: 0.0052\nEpoch 19/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0051\nEpoch 20/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0050 - val_loss: 0.0079\nEpoch 21/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0047 - val_loss: 0.0063\nEpoch 22/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0046 - val_loss: 0.0051\nEpoch 23/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0048 - val_loss: 0.0074\nEpoch 24/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0053\nEpoch 25/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0049 - val_loss: 0.0051\nEpoch 26/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0046 - val_loss: 0.0070\nEpoch 27/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.0053\nEpoch 28/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0081\nEpoch 29/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0071\nEpoch 30/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.0053\nEpoch 31/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0045 - val_loss: 0.0094\nEpoch 32/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0066\nEpoch 33/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0042 - val_loss: 0.0057\nEpoch 34/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0045 - val_loss: 0.0071\nEpoch 35/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0037 - val_loss: 0.0056\nEpoch 36/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0039 - val_loss: 0.0081\nEpoch 37/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 0.0039 - val_loss: 0.0076\nEpoch 38/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0061\nEpoch 39/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0038 - val_loss: 0.0072\nEpoch 40/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0063\nEpoch 41/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0043 - val_loss: 0.0039\nEpoch 42/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 0.0039 - val_loss: 0.0086\nEpoch 43/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0085\nEpoch 44/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0055\nEpoch 45/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.0039 - val_loss: 0.0039\nEpoch 46/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 0.0038 - val_loss: 0.0070\nEpoch 47/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0051\nEpoch 48/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.0040 - val_loss: 0.0072\nEpoch 49/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 0.0039 - val_loss: 0.0052\nEpoch 50/50\n\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 0.0038 - val_loss: 0.0056\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\nFold 16 - RMSE: 0.07458205740243531\nFold 16 - R2: 0.8892870544456014\n\nTraining fold 17...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - loss: 1.1876 - val_loss: 0.0031\nEpoch 2/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0114 - val_loss: 0.0049\nEpoch 3/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0113 - val_loss: 0.0019\nEpoch 4/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.0087 - val_loss: 0.0018\nEpoch 5/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0088 - val_loss: 0.0015\nEpoch 6/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0077 - val_loss: 0.0019\nEpoch 7/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0073 - val_loss: 0.0030\nEpoch 8/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0070 - val_loss: 0.0015\nEpoch 9/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0059 - val_loss: 0.0022\nEpoch 10/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0067 - val_loss: 0.0017\nEpoch 11/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0058 - val_loss: 0.0018\nEpoch 12/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0062 - val_loss: 0.0015\nEpoch 13/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0057 - val_loss: 0.0013\nEpoch 14/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0062 - val_loss: 0.0014\nEpoch 15/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0055 - val_loss: 0.0019\nEpoch 16/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0057 - val_loss: 0.0017\nEpoch 17/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0057 - val_loss: 0.0022\nEpoch 18/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0021\nEpoch 19/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0032\nEpoch 20/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0049 - val_loss: 0.0015\nEpoch 21/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0048 - val_loss: 0.0014\nEpoch 22/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0015\nEpoch 23/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0018\nEpoch 24/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0016\nEpoch 25/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0016\nEpoch 26/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0039 - val_loss: 0.0016\nEpoch 27/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0018\nEpoch 28/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0024\nEpoch 29/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0020\nEpoch 30/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0016\nEpoch 31/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0021\nEpoch 32/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0016\nEpoch 33/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0024\nEpoch 34/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0016\nEpoch 35/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0037 - val_loss: 0.0022\nEpoch 36/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0017\nEpoch 37/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0021\nEpoch 38/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0020\nEpoch 39/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0018\nEpoch 40/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0020\nEpoch 41/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0022\nEpoch 42/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0021\nEpoch 43/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0020\nEpoch 44/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0035 - val_loss: 0.0027\nEpoch 45/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0039 - val_loss: 0.0020\nEpoch 46/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0017\nEpoch 47/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0037 - val_loss: 0.0016\nEpoch 48/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0015\nEpoch 49/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0016\nEpoch 50/50\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0022\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 17 - RMSE: 0.04654430107043137\nFold 17 - R2: 0.9406156071686402\n\nTraining fold 18...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 1.8745 - val_loss: 0.0016\nEpoch 2/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0199 - val_loss: 0.0015\nEpoch 3/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0147 - val_loss: 0.0015\nEpoch 4/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0104 - val_loss: 0.0015\nEpoch 5/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0099 - val_loss: 0.0015\nEpoch 6/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0089 - val_loss: 0.0013\nEpoch 7/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0074 - val_loss: 0.0023\nEpoch 8/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0074 - val_loss: 0.0014\nEpoch 9/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0069 - val_loss: 0.0017\nEpoch 10/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0063 - val_loss: 0.0023\nEpoch 11/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0063 - val_loss: 0.0030\nEpoch 12/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0053 - val_loss: 0.0018\nEpoch 13/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0055 - val_loss: 0.0022\nEpoch 14/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0051 - val_loss: 0.0023\nEpoch 15/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0034\nEpoch 16/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0032\nEpoch 17/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0047 - val_loss: 0.0017\nEpoch 18/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0044 - val_loss: 0.0033\nEpoch 19/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0046 - val_loss: 0.0027\nEpoch 20/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0038\nEpoch 21/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0032\nEpoch 22/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0025\nEpoch 23/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0020\nEpoch 24/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0038\nEpoch 25/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0018\nEpoch 26/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0021\nEpoch 27/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0038\nEpoch 28/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0044\nEpoch 29/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0036 - val_loss: 0.0035\nEpoch 30/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0038\nEpoch 31/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0036 - val_loss: 0.0047\nEpoch 32/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0023\nEpoch 33/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0030\nEpoch 34/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0030\nEpoch 35/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 36/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0021\nEpoch 37/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0035\nEpoch 38/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0038\nEpoch 39/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0036\nEpoch 40/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0036\nEpoch 41/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0034 - val_loss: 0.0032\nEpoch 42/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0031 - val_loss: 0.0033\nEpoch 43/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0022\nEpoch 44/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0032\nEpoch 45/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0023\nEpoch 46/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0027\nEpoch 47/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0034 - val_loss: 0.0023\nEpoch 48/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0025\nEpoch 49/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0022\nEpoch 50/50\n\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0037 - val_loss: 0.0037\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\nFold 18 - RMSE: 0.06062652426471473\nFold 18 - R2: 0.862650754653054\n\nTraining fold 19...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 0.4127 - val_loss: 0.0057\nEpoch 2/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0125 - val_loss: 0.0020\nEpoch 3/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0100 - val_loss: 0.0022\nEpoch 4/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0078 - val_loss: 0.0022\nEpoch 5/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0079 - val_loss: 0.0033\nEpoch 6/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0066 - val_loss: 0.0022\nEpoch 7/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0060 - val_loss: 0.0056\nEpoch 8/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0030\nEpoch 9/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0055 - val_loss: 0.0040\nEpoch 10/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0057 - val_loss: 0.0020\nEpoch 11/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0049 - val_loss: 0.0021\nEpoch 12/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0043 - val_loss: 0.0034\nEpoch 13/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 0.0046 - val_loss: 0.0018\nEpoch 14/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0017\nEpoch 15/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0039 - val_loss: 0.0021\nEpoch 16/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0026\nEpoch 17/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0046 - val_loss: 0.0028\nEpoch 18/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0020\nEpoch 19/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0017\nEpoch 20/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0015\nEpoch 21/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0015\nEpoch 22/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0013\nEpoch 23/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0012\nEpoch 24/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0096\nEpoch 25/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0064 - val_loss: 0.0024\nEpoch 26/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0019\nEpoch 27/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0018\nEpoch 28/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0022\nEpoch 29/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0022\nEpoch 30/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0013\nEpoch 31/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0011\nEpoch 32/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0028\nEpoch 33/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0029\nEpoch 34/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.0041 - val_loss: 0.0032\nEpoch 35/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0025\nEpoch 36/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0018\nEpoch 37/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0024\nEpoch 38/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0017\nEpoch 39/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0011\nEpoch 40/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0016\nEpoch 41/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0028\nEpoch 42/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0020\nEpoch 43/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0020\nEpoch 44/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 9.7285e-04\nEpoch 45/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0016\nEpoch 46/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 47/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0015\nEpoch 48/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0013\nEpoch 49/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0011\nEpoch 50/50\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0010\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\nFold 19 - RMSE: 0.03218104040587087\nFold 19 - R2: 0.9614818412404816\n\nTraining fold 20...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 1.2341 - val_loss: 0.0135\nEpoch 2/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0141 - val_loss: 0.0086\nEpoch 3/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0116 - val_loss: 0.0041\nEpoch 4/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0117 - val_loss: 0.0032\nEpoch 5/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0086 - val_loss: 0.0031\nEpoch 6/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0081 - val_loss: 0.0029\nEpoch 7/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0073 - val_loss: 0.0021\nEpoch 8/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.0070 - val_loss: 0.0023\nEpoch 9/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0070 - val_loss: 0.0019\nEpoch 10/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0063 - val_loss: 0.0019\nEpoch 11/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0061 - val_loss: 0.0021\nEpoch 12/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0054 - val_loss: 0.0018\nEpoch 13/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0047 - val_loss: 0.0017\nEpoch 14/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0015\nEpoch 15/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0016\nEpoch 16/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0019\nEpoch 17/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0017\nEpoch 18/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0037 - val_loss: 0.0014\nEpoch 19/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0035 - val_loss: 0.0015\nEpoch 20/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0015\nEpoch 21/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0032 - val_loss: 0.0019\nEpoch 22/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0018\nEpoch 23/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0013\nEpoch 24/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0012\nEpoch 25/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0012\nEpoch 26/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0012\nEpoch 27/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0012\nEpoch 28/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0014\nEpoch 29/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0011\nEpoch 30/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0013\nEpoch 31/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0021\nEpoch 32/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0012\nEpoch 33/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0031 - val_loss: 0.0017\nEpoch 34/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0011\nEpoch 35/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0014\nEpoch 36/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0011\nEpoch 37/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 0.0027\nEpoch 38/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0014\nEpoch 39/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0028 - val_loss: 0.0015\nEpoch 40/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0014\nEpoch 41/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0012\nEpoch 42/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0028 - val_loss: 0.0011\nEpoch 43/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0031 - val_loss: 9.8926e-04\nEpoch 44/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0028 - val_loss: 0.0010\nEpoch 45/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0028 - val_loss: 0.0021\nEpoch 46/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0014\nEpoch 47/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0013\nEpoch 48/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0030 - val_loss: 0.0011\nEpoch 49/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0028 - val_loss: 0.0012\nEpoch 50/50\n\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 8.3117e-04\n\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\nFold 20 - RMSE: 0.028829985994027075\nFold 20 - R2: 0.9656670990866459\n\nAverage RMSE across all folds: 0.06428874385139885\nAverage R2 across all folds: 0.8383840062530398\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}